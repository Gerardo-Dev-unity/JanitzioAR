<!doctype html>
<html lang="es">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width,initial-scale=1.0"/>
  <title>AR.js con stream propio (iOS fix)</title>

  <!-- A-Frame + AR.js (build aframe) -->
  <script src="https://cdn.jsdelivr.net/gh/AR-js-org/AR.js/aframe/build/aframe-ar.min.js"></script>

  <style>
    html,body{margin:0;height:100%;background:#000;color:#fff;font-family:system-ui}
    #start{position:fixed;inset:0;display:flex;flex-direction:column;align-items:center;justify-content:center;gap:12px;background:#000;z-index:9999;text-align:center;padding:24px}
    #btn{appearance:none;border:0;background:#16a34a;color:#fff;padding:12px 18px;border-radius:10px;font-weight:700;font-size:16px}
    #ui{position:fixed;left:8px;top:8px;z-index:10;background:rgba(0,0,0,.55);padding:8px 10px;border-radius:8px}
    #log{position:fixed;right:8px;bottom:8px;background:rgba(0,0,0,.6);color:#0f0;padding:8px;border-radius:8px;font:12px/1 monospace;z-index:99999;max-width:90vw}
    video#cam{position:fixed;left:-9999px;top:-9999px; /* oculto, pero presente */}
  </style>
</head>
<body>

  <!-- Tap-to-start -->
  <div id="start">
    <h2 style="margin:0">Toca para iniciar AR</h2>
    <div style="opacity:.8">Usaremos el mismo flujo que funcionó en camera-test.</div>
    <button id="btn">Iniciar</button>
  </div>

  <div id="ui" style="display:none">
    <b>AR.js con video propio</b><br/>Apunta al marcador HIRO (luego cambiamos al tuyo).
  </div>

  <div id="log">Log…</div>

  <!-- Video que recibirá el stream (como en camera-test) -->
  <video id="cam" playsinline autoplay muted></video>

  <!-- Aquí inyectaremos la escena -->
  <div id="root"></div>

  <script>
    const start = document.getElementById('start');
    const ui    = document.getElementById('ui');
    const root  = document.getElementById('root');
    const vid   = document.getElementById('cam');
    const logBox= document.getElementById('log');
    const log = m => { console.log(m); logBox.textContent = m; };

    async function openCamera() {
      try {
        const stream = await navigator.mediaDevices.getUserMedia({
          video: {
            facingMode: { ideal: "environment" },
            width: { ideal: 1280 }, height: { ideal: 720 }
          },
          audio: false
        });
        vid.srcObject = stream;
        await vid.play().catch(()=>{});
        return new Promise(resolve=>{
          const ready = () => { vid.removeEventListener('loadedmetadata', ready); resolve(); };
          vid.addEventListener('loadedmetadata', ready);
        });
      } catch(e) {
        log('❌ getUserMedia error: '+e.name+' — '+e.message);
        throw e;
      }
    }

    document.getElementById('btn').addEventListener('click', async () => {
      start.style.display='none';
      log('⏳ Abriendo cámara…');
      await openCamera();
      log('✅ Cámara OK — inyectando escena AR');

      ui.style.display='block';

      // Inyectamos escena diciendo a AR.js que use NUESTRO video
      // OJO: usamos sourceType: video y sourceUrl: #cam
      root.innerHTML = `
        <a-scene
          embedded
          renderer="antialias: true; colorManagement: true; physicallyCorrectLights: true"
          arjs="trackingMethod: best; sourceType: video; sourceUrl: #cam; debugUIEnabled: false">

          <!-- Primero probamos con HIRO; luego cambiaremos a tu .patt -->
          <a-marker preset="hiro">
            <a-box position="0 0.5 0" depth="0.5" height="0.5" width="0.5" color="red"></a-box>
          </a-marker>

          <a-entity camera></a-entity>
        </a-scene>
      `;

      // Chequeo de que AR.js vea el <video> y esté produciendo frames
      setTimeout(() => {
        const rs = ['HAVE_NOTHING','HAVE_METADATA','HAVE_CURRENT_DATA','HAVE_FUTURE_DATA','HAVE_ENOUGH_DATA'];
        log('readyState video=' + (rs[vid.readyState]||vid.readyState));
      }, 1200);
    });
  </script>
</body>
</html>
